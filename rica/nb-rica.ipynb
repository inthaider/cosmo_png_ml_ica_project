{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RICA: Reconstruction Independent Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reproduces Reconstruction ICA with PyTorch\n",
    "\n",
    "1. Modify `torchvision_path_cifar10` to your cifar10 path, or just any folder (it will download dataset automatically)\n",
    "2. If you do not have a GPU, set `use_gpu=False`. It's going to take more than a few minutes.. If you want to speed\n",
    "   things up a bit:\n",
    "   - change lambdas to just [2.4], this runs the script with a single lambda value only, and gives decent result\n",
    "   - maybe reduce num_epochs to 100\n",
    "   - if you want to run all the lambda values\n",
    "     - reduce patch_size to 8, which is probably 2x faster than 16\n",
    "     - reduce num_epochs to 40\n",
    "\"\"\"\n",
    "\n",
    "use_gpu    = False              # if to use GPU\n",
    "num_epochs = 100                # how long each lambda runs, 200 is probably overkill\n",
    "num_steps  = 20                 # how many lambdas to try\n",
    "patch_size = 16                 # patch size to extract, 16 is max\n",
    "weight_size= patch_size**2      # weight size is number of pixels in a patch (do not change)\n",
    "num_filters = weight_size       # complete-ICA has same number of filters as there are pixels\n",
    "# lambdas = [l*0.4 for l in range(1,num_steps)] # the lambda values will be tried one by one\n",
    "lambdas = [2.4] # the lambda values will be tried one by one\n",
    "torchvision_path_cifar10 = 'torchvision_cifar10/'\n",
    "batch_size = 1000\n",
    "\n",
    "def maybe_gpu(data):\n",
    "    return data.cuda() if use_gpu else data\n",
    "\n",
    "# use cifar10 as dataset\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "        torchvision_path_cifar10, \n",
    "        train=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.469, 0.481, 0.451], std=[0.239,0.245,0.272])\n",
    "            # normalize to 0-mean, unit-variance\n",
    "        ]), \n",
    "        download=True)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "\n",
    "# load the entire dataset into a single Tensor, this speeds things up quite a bit\n",
    "data_all = []\n",
    "for imgs, labels in loader:\n",
    "    data_all.append(imgs)\n",
    "data_all = torch.cat(data_all)      # merge into single tensor\n",
    "data_all = data_all.mean(1)         # make black-white\n",
    "data_all = maybe_gpu(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data_all.size(0)\n",
    "num_batches = int(data_size/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 32, 32])\n",
      "256\n",
      "256\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_all.shape)\n",
    "print(weight_size)\n",
    "print(num_filters)\n",
    "print(type(data_all.size(0)))\n",
    "data_all.size(0)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(len(dataset))\n",
    "# # print(dataset.targets)\n",
    "# print(len(next(iter(dataset))))\n",
    "# # z_chisq_npy = np.load(\"pnong/np-1d_zeta_fields/z_chisq_seeds741785_501982.npy\")\n",
    "# # z_chisq = torch.Tensor(z_chisq_npy)\n",
    "# # dataset = TensorDataset(z_chisq) # create your datset\n",
    "# # loader = DataLoader(dataset) # create your dataloader\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=1000, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "# # load the entire dataset into a single Tensor, this speeds things up quite a bit\n",
    "# data_all = []\n",
    "# for imgs, labels in loader:\n",
    "#     data_all.append(imgs)\n",
    "# data_all = torch.cat(data_all)      # merge into single tensor\n",
    "# print(len(data_all))\n",
    "# # print(dataset.targets)\n",
    "# print(len(next(iter(data_all))))\n",
    "# # data_all = data_all.mean(1)         # make black-white\n",
    "# # data_all = maybe_gpu(data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.011399745941162\n",
      "0.15843912959098816\n",
      "0.6311457753181458\n",
      "1\n",
      "0.6897774934768677\n",
      "0.05696240812540054\n",
      "0.553067684173584\n",
      "2\n",
      "0.5739295482635498\n",
      "0.034652501344680786\n",
      "0.4907635748386383\n",
      "3\n",
      "0.49961450695991516\n",
      "0.024129385128617287\n",
      "0.4417039752006531\n",
      "4\n",
      "0.45104655623435974\n",
      "0.018258504569530487\n",
      "0.4072261452674866\n",
      "5\n",
      "0.42007017135620117\n",
      "0.014783014543354511\n",
      "0.38459092378616333\n",
      "6\n",
      "0.39749059081077576\n",
      "0.012620189227163792\n",
      "0.36720213294029236\n",
      "7\n",
      "0.3802899718284607\n",
      "0.011223114095628262\n",
      "0.35335448384284973\n",
      "8\n",
      "0.3664909303188324\n",
      "0.010323027148842812\n",
      "0.34171566367149353\n",
      "9\n",
      "0.3549286723136902\n",
      "0.009826271794736385\n",
      "0.3313456177711487\n",
      "10\n",
      "0.3466581106185913\n",
      "0.0099002905189991\n",
      "0.32289740443229675\n",
      "11\n",
      "0.34012675285339355\n",
      "0.010082520544528961\n",
      "0.31592869758605957\n",
      "12\n",
      "0.3341059386730194\n",
      "0.010154243558645248\n",
      "0.3097357451915741\n",
      "13\n",
      "0.33015984296798706\n",
      "0.010510358959436417\n",
      "0.3049349784851074\n",
      "14\n",
      "0.3274437189102173\n",
      "0.010794878005981445\n",
      "0.30153602361679077\n",
      "15\n",
      "0.32568126916885376\n",
      "0.01094879861921072\n",
      "0.2994041442871094\n",
      "16\n",
      "0.32401883602142334\n",
      "0.011326231062412262\n",
      "0.29683586955070496\n",
      "17\n",
      "0.32439908385276794\n",
      "0.011682780459523201\n",
      "0.29636040329933167\n",
      "18\n",
      "0.32624587416648865\n",
      "0.011570609174668789\n",
      "0.2984763979911804\n",
      "19\n",
      "0.32983312010765076\n",
      "0.011897369287908077\n",
      "0.3012794256210327\n",
      "20\n",
      "0.3293085992336273\n",
      "0.01182345300912857\n",
      "0.3009323179721832\n",
      "21\n",
      "0.32337069511413574\n",
      "0.0119235310703516\n",
      "0.2947542071342468\n",
      "22\n",
      "0.326772540807724\n",
      "0.01174570806324482\n",
      "0.29858285188674927\n",
      "23\n",
      "0.3259889483451843\n",
      "0.011803796514868736\n",
      "0.29765984416007996\n",
      "24\n",
      "0.32628875970840454\n",
      "0.011958674527704716\n",
      "0.29758793115615845\n",
      "25\n",
      "0.33070671558380127\n",
      "0.01178179681301117\n",
      "0.3024303913116455\n",
      "26\n",
      "0.32751497626304626\n",
      "0.011967044323682785\n",
      "0.29879406094551086\n",
      "27\n",
      "0.3278614282608032\n",
      "0.011750252917408943\n",
      "0.2996608316898346\n",
      "28\n",
      "0.3321695625782013\n",
      "0.01197692472487688\n",
      "0.3034249544143677\n",
      "29\n",
      "0.3224014341831207\n",
      "0.012027367949485779\n",
      "0.2935357391834259\n",
      "30\n",
      "0.3274410367012024\n",
      "0.011802880093455315\n",
      "0.2991141080856323\n",
      "31\n",
      "0.3309986889362335\n",
      "0.01170293241739273\n",
      "0.302911639213562\n",
      "32\n",
      "0.32942840456962585\n",
      "0.011589719913899899\n",
      "0.30161306262016296\n",
      "33\n",
      "0.3219947814941406\n",
      "0.01191807258874178\n",
      "0.2933914065361023\n",
      "34\n",
      "0.32266971468925476\n",
      "0.011690767481923103\n",
      "0.2946118712425232\n",
      "35\n",
      "0.3291154205799103\n",
      "0.011703535914421082\n",
      "0.30102694034576416\n",
      "36\n",
      "0.32391148805618286\n",
      "0.01154368743300438\n",
      "0.29620662331581116\n",
      "37\n",
      "0.32257238030433655\n",
      "0.011664755642414093\n",
      "0.2945769727230072\n",
      "38\n",
      "0.3248419761657715\n",
      "0.011930426582694054\n",
      "0.2962089478969574\n",
      "39\n",
      "0.3236725330352783\n",
      "0.011382265016436577\n",
      "0.29635509848594666\n",
      "40\n",
      "0.3205767571926117\n",
      "0.011553405784070492\n",
      "0.2928485870361328\n",
      "41\n",
      "0.3235999643802643\n",
      "0.011606749147176743\n",
      "0.29574376344680786\n",
      "42\n",
      "0.3295687437057495\n",
      "0.012060897424817085\n",
      "0.3006225824356079\n",
      "43\n",
      "0.3282003104686737\n",
      "0.01182407233864069\n",
      "0.29982253909111023\n",
      "44\n",
      "0.3255910575389862\n",
      "0.012014287523925304\n",
      "0.296756774187088\n",
      "45\n",
      "0.32386690378189087\n",
      "0.01156381331384182\n",
      "0.2961137592792511\n",
      "46\n",
      "0.3237729072570801\n",
      "0.011685413308441639\n",
      "0.2957279086112976\n",
      "47\n",
      "0.3289686143398285\n",
      "0.012060584500432014\n",
      "0.3000231981277466\n",
      "48\n",
      "0.32384660840034485\n",
      "0.011602391488850117\n",
      "0.2960008680820465\n",
      "49\n",
      "0.324903279542923\n",
      "0.011892789974808693\n",
      "0.296360582113266\n",
      "50\n",
      "0.3243487775325775\n",
      "0.011498908512294292\n",
      "0.2967514097690582\n",
      "51\n",
      "0.3231957256793976\n",
      "0.011725441552698612\n",
      "0.29505467414855957\n",
      "52\n",
      "0.3291957378387451\n",
      "0.012169278226792812\n",
      "0.2999894618988037\n",
      "53\n",
      "0.3292059898376465\n",
      "0.011797614395618439\n",
      "0.3008917272090912\n",
      "54\n",
      "0.3244526982307434\n",
      "0.011893673799932003\n",
      "0.2959078848361969\n",
      "55\n",
      "0.321718692779541\n",
      "0.011568084359169006\n",
      "0.2939552962779999\n",
      "56\n",
      "0.3266183137893677\n",
      "0.011974375694990158\n",
      "0.29787981510162354\n",
      "57\n",
      "0.3194403350353241\n",
      "0.011501905508339405\n",
      "0.291835755109787\n",
      "58\n",
      "0.3212757706642151\n",
      "0.011724509298801422\n",
      "0.29313695430755615\n",
      "59\n",
      "0.32489070296287537\n",
      "0.011555883102118969\n",
      "0.29715657234191895\n",
      "60\n",
      "0.3193850517272949\n",
      "0.011576813645660877\n",
      "0.29160070419311523\n",
      "61\n",
      "0.32249578833580017\n",
      "0.011931953951716423\n",
      "0.2938590943813324\n",
      "62\n",
      "0.3281343877315521\n",
      "0.011839820072054863\n",
      "0.29971882700920105\n",
      "63\n",
      "0.32208871841430664\n",
      "0.01149353664368391\n",
      "0.29450422525405884\n",
      "64\n",
      "0.32448121905326843\n",
      "0.011434545740485191\n",
      "0.29703831672668457\n",
      "65\n",
      "0.3246207535266876\n",
      "0.011558189988136292\n",
      "0.2968811094760895\n",
      "66\n",
      "0.3241749405860901\n",
      "0.011517447419464588\n",
      "0.29653307795524597\n",
      "67\n",
      "0.32890379428863525\n",
      "0.011752950958907604\n",
      "0.3006967008113861\n",
      "68\n",
      "0.329263299703598\n",
      "0.011889010667800903\n",
      "0.3007296621799469\n",
      "69\n",
      "0.3311097323894501\n",
      "0.011631079949438572\n",
      "0.30319514870643616\n",
      "70\n",
      "0.3247253894805908\n",
      "0.011610171757638454\n",
      "0.2968609631061554\n",
      "71\n",
      "0.3260951042175293\n",
      "0.011622225865721703\n",
      "0.2982017695903778\n",
      "72\n",
      "0.3267354667186737\n",
      "0.011449333280324936\n",
      "0.2992570698261261\n",
      "73\n",
      "0.3242899179458618\n",
      "0.01152023021131754\n",
      "0.29664137959480286\n",
      "74\n",
      "0.32591456174850464\n",
      "0.011657307855784893\n",
      "0.2979370355606079\n",
      "75\n",
      "0.3303379416465759\n",
      "0.011847220361232758\n",
      "0.3019046187400818\n",
      "76\n",
      "0.3215114176273346\n",
      "0.011598492972552776\n",
      "0.293675035238266\n",
      "77\n",
      "0.3295072317123413\n",
      "0.01150108128786087\n",
      "0.3019046485424042\n",
      "78\n",
      "0.3250126540660858\n",
      "0.011392722837626934\n",
      "0.2976701259613037\n",
      "79\n",
      "0.32284167408943176\n",
      "0.011525263078510761\n",
      "0.2951810359954834\n",
      "80\n",
      "0.32578831911087036\n",
      "0.011913511902093887\n",
      "0.2971958816051483\n",
      "81\n",
      "0.3227729797363281\n",
      "0.011322404257953167\n",
      "0.29559922218322754\n",
      "82\n",
      "0.3234235346317291\n",
      "0.0114753944799304\n",
      "0.29588258266448975\n",
      "83\n",
      "0.3245536684989929\n",
      "0.011387602426111698\n",
      "0.29722341895103455\n",
      "84\n",
      "0.3260951638221741\n",
      "0.011714053340256214\n",
      "0.2979814410209656\n",
      "85\n",
      "0.3271171450614929\n",
      "0.01196081843227148\n",
      "0.29841119050979614\n",
      "86\n",
      "0.31978750228881836\n",
      "0.011422361247241497\n",
      "0.2923738360404968\n",
      "87\n",
      "0.3205636441707611\n",
      "0.011247152462601662\n",
      "0.29357048869132996\n",
      "88\n",
      "0.32622045278549194\n",
      "0.01162603311240673\n",
      "0.29831796884536743\n",
      "89\n",
      "0.3237250745296478\n",
      "0.011370018124580383\n",
      "0.29643702507019043\n",
      "90\n",
      "0.32307004928588867\n",
      "0.011243121698498726\n",
      "0.29608654975891113\n",
      "91\n",
      "0.32454055547714233\n",
      "0.011573635041713715\n",
      "0.2967638373374939\n",
      "92\n",
      "0.3252294659614563\n",
      "0.011475913226604462\n",
      "0.29768726229667664\n",
      "93\n",
      "0.3232693672180176\n",
      "0.011166827753186226\n",
      "0.29646897315979004\n",
      "94\n",
      "0.3250100016593933\n",
      "0.011317215859889984\n",
      "0.2978486716747284\n",
      "95\n",
      "0.3247106671333313\n",
      "0.011688643135130405\n",
      "0.296657919883728\n",
      "96\n",
      "0.32635846734046936\n",
      "0.01131466031074524\n",
      "0.2992032766342163\n",
      "97\n",
      "0.3217599093914032\n",
      "0.011722838506102562\n",
      "0.2936250865459442\n",
      "98\n",
      "0.32437664270401\n",
      "0.011295068077743053\n",
      "0.29726848006248474\n",
      "99\n",
      "0.3282682001590729\n",
      "0.011653580702841282\n",
      "0.30029961466789246\n",
      "Finished lambda=2.4\n"
     ]
    }
   ],
   "source": [
    "def doit(lambd=1, epochs=num_epochs):\n",
    "    weight    = Parameter(maybe_gpu(1.0/patch_size*torch.Tensor(weight_size, num_filters).normal_()))\n",
    "    optimizer = torch.optim.RMSprop([weight], 0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(num_batches):\n",
    "            # select batch\n",
    "            imgs = data_all[batch*1000:(batch+1)*1000]\n",
    "            # capture a few patches\n",
    "            patches = []\n",
    "            for x,y in itertools.product([0, 8, 16],[0,8,16]):\n",
    "                patches.append(imgs[:, y:y+patch_size, x:x+patch_size])\n",
    "            patches = Variable(maybe_gpu(torch.cat(patches)))\n",
    "            patches = patches.view(patches.size(0), -1)\n",
    "            latents= patches.matmul(weight)\n",
    "            output = latents.matmul(weight.t())\n",
    "            diff = output - patches\n",
    "            loss_recon = (diff * diff).mean()\n",
    "            loss_latent= latents.abs().mean()\n",
    "            loss = lambd * loss_recon + loss_latent\n",
    "            # optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(epoch)\n",
    "        print(loss.item())\n",
    "        print(loss_recon.item())\n",
    "        print(loss_latent.item())\n",
    "    weight_images = weight.data.t().contiguous().view(num_filters, 1, patch_size, patch_size).cpu()\n",
    "    vutils.save_image(weight_images, 'rica_weight_images_{}.jpg'.format(lambd), nrow=patch_size, normalize=True)\n",
    "    print('Finished lambda={}'.format(lambd))\n",
    "\n",
    "    return weight_images\n",
    "\n",
    "\n",
    "for l in lambdas:\n",
    "    weight = doit(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('cosmic_nong')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6781a5192c0b6eb04b7b9348c292a0e39c03bca97c5ebc8f1c4565fff6f215ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
